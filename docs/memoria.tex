\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\usepackage[spanish, es-tabla]{babel}
\usepackage{graphicx}
\usepackage[style=apa]{biblatex}
\addbibresource{references.bib}
\usepackage[hidelinks]{hyperref}
\usepackage[left=3cm, right=3cm, top=2cm]{geometry}
\usepackage{subcaption}

% subsubsubsection
\usepackage{titlesec}
\setcounter{secnumdepth}{4}
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
% 


% Confusion matrix
% Fuente: https://tex.stackexchange.com/a/552743
\usepackage{multirow}
\usepackage{textcomp}
% 


\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\title{\textbf{\huge Reconocimiento automático de notas del piano}}
% \title{\textbf{\huge Automatic recoginition of piano notes: A comparison between ANNs, SVMs and DTs}}
\author{{David Rodríguez Bacelar} \\[0.25cm] {Kevin Millán Canchapoma} \\[0.25cm]{Luca D'angelo Sabín} \\[0.25cm]{Jorge Hermo González}}
\date{\today}

\begin{document}

\maketitle
\HRule
\bigskip\bigskip\bigskip\bigskip\bigskip\bigskip
\begin{figure}[h!]
	\centering
	\includegraphics[height=180px]{udc.jpg}
	\label{fig:diagram1}
\end{figure}

\newpage

\tableofcontents

\newpage
\section{Introducción}

A raíz de la pandemia, el aumento del interés por el aprendizaje en diferentes ámbitos llegó tambíen a la música, y con él, la aparición
de herramientas para aprender a tocar diferentes instrumentos de forma autodidacta.

\bigskip
Así, para cualquiera que esté aprendiendo, el escuchar una canción que te gusta e intentar tocarla es algo que acaba siendo un proceso
frustante y que requiere una gran cantidad de horas intentando sacar las notas que la componen.

\bigskip
Nuestro sistema se encargaría entonces de reconocer y diferenciar a partir de audios las notas de una pieza de piano
pudiendo, en un futuro, ser capaz de detectar acordes y tonalidades, siendo útil en aplicaciones como Spotify, Tidal... Para ello, haremos uso
de diferentes técnicas de aprendizaje automático como las redes de neuronas artificiales, árboles de decisión y máquinas de soporte vectorial,
comparando su rendimiento y eligiendo la que mejor resultados nos ofrezca.

\bigskip
A lo largo de esta memoria analizaremos a fondo el problema a resolver en la Sección \ref{Descripción del problema}, desarrollaremos las diferentes soluciones en la
Sección \ref{Desarrollo}, hablaremos sobre las conclusiones del trabajo en la Sección \ref{Conclusiones} y finalizaremos comentando las aplicaciones al mundo
real en la Sección \ref{Trabajo futuro}. También se podrá consultar las bibliografía utilizada en la Sección \ref{Análisis bibliográfico} y \ref{Bibliografía}.

\subsection{Glosario}
\label{Glosario}
\begin{itemize}
	\item Sample: muestra de carácter musical
	\item Cover: Reinterpretación de una canción por parte de alguien diferente al que la compuso.
	\item VP: Verdadero positivo
	\item VN: Verdadero negativo
	\item FP: Falso positivo
	\item FN: Falso negativo
	\item RNA: Red de neuronas artificial.
	\item SVM: \textit{Support Vector Machine} (Máquina de soporte vectorial).
	\item kNN: \textit{K-nearest neighbors} (k vecinos más cercanos).
	\item poly: \textit{Kernel} polinomial.
	\item rbf: \textit{Kernel} de función de base radial (Gaussiano)
	\item sigmoid: \textit{Kernel} sigmoidal
	% \item TF: transformada de Fourier
\end{itemize}

\newpage

\section{Descripción del problema}
\label{Descripción del problema}

Nuestro sistema se centrará en reconocer, a partir de un audio, la nota del piano que se está tocando. Escogimos este instrumento por la cantidad de recursos
que podemos encontrar y por su naturaleza invariable al ser tocada por una u otra persona.

\bigskip
Dada la naturaleza de nuestro sistema, descartamos utilizar la especificidad o la sensibilidad ya que nos es indiferente las clases en las que se clasifiquen
las notas (el coste de un falso positivo o un falso negativo es el mismo).

\bigskip
Así, como solo nos interesa una correcta clasificación global, pensamos en utilizar la precisión, la cual sigue la fórmula:

\begin{equation}
	Precision = \frac{VN + VP}{(VN + FN + VP + FP)}
\end{equation}

\smallskip
El incoveniente de esta métrica está en que si tenemos un conjunto de patrones desbalanceado (gran diferencia en el número de
patrones positivos y negativos), la precisión podría alcanzar valores muy altos con sistemas que clasifiquen todos los patrones en la clase con mayor número de ellos
en el entrenamiento.

\bigskip
La métrica que utilizaremos entonces para valorar los resultados obtenidos y que palia los problemas
mencionados anteriormente será la \textbf{F1-score}. Esta se corresponde con la media armónica de la sensibilidad y el
valor predictivo positivo y está caracterizada por la fórmula: 

\begin{equation}
	F1-Score = \left(\frac{Sensibilidad^{-1} + VPP^{-1}}{2}\right)^{-1}
\end{equation}

donde, 
\begin{equation}
	Sensibilidad = \frac{VP}{(FN + VP)}
\end{equation}

\begin{equation}
	VPP = \frac{VP}{(VP + FP)}, 
\end{equation}

\smallskip
Quizá el único inconveniente de esta métrica es su difícil interpretación, más allá de comparar los valores que ofrecen diferentes sistemas.
El valor más alto que puede alcanzar es de 1 (todos los patrones se clasificaron correctamente) y el más bajo es de 0 (todos los patrones se clasificaron
incorrectamente). Entonces, para facilitar la interpretación de la métrica, también se mostrará la precisión de cada modelo, pero se utilizará
el F1-Score para determinar el mejor modelo.

\subsection{Restricciones}
\bigskip
Como única restricción, en dicho audio solo puede haber una nota sonando a la vez para que el sistema sea capaz de reconocerla correctamente.

\subsection{Características}
\bigskip
La base de datos con la que contamos tiene un total de 5.406 audios con una media de más de 50 \textit{samples} por cada una de las 85 notas del piano (a partir de \textit{C1}), tocadas
desde posiciones e intensidades distintas y grabadas con micrófonos diferentes. Dichos \textit{samples} están en formato \textit{.wav} en estéreo, con un 
\textit{bitrate} de \textit{2304kbps}, \textit{24 bits per sample} y un \textit{sample rate} de \textit{48kHz}. Todo ello ocupa un total de \textit{34.5GB} en disco.
La duración media de los \textit{samples} es de aproximadamente 6 segundos.

\bigskip
El origen de la base de datos es una librería de piano de la compañía \textit{FluffyAudio} \textit{\url{https://www.fluffyaudio.com/shop/scoringpiano/}} 
grabada en 2016 y pensada para jazz, música clásica y bandas sonoras.

\section{Análisis bibliográfico}
\label{Análisis bibliográfico}
Para profundizar en el tema antes de abordarlo, en esta sección se analizan diferentes artículos científicos relacionados con la inteligencia
artificial y el reconocimiento de audio, ya sea específicamente relacionado o no con el mundo del reconocimiento de piezas o notas musicales.

\bigskip
Trabajos como el de \cite{osmalsky2012neural} nos aportan nuevos enfoques, 
en el que, en lugar de detectar las notas por separado, analizan todo el espectro de frecuencias para poder reconocer acordes completos de diferentes instrumentos;
utilizan una técnica llamada Pitch Class Profile (PCP), que obtiene las relaciones energéticas de cada nota en la escala a partir de un audio.

\bigskip
Además, como resumen \cite{benetos2018automatic},
a pesar del estado avanzado de la transcripción automática de canciones, aún están presentes retos tales como la independencia de los intrumentos, de los estilos
musicales o la interpretación de la expresividad.

\bigskip
Otros trabajos mas antiguos como los de \cite{foo1999recognition}, describen un algoritmo capaz de reconocer notas
de un piano a partir de piezas sintetizadas o acústicas, que son digitalmente muestreadas y transformadas al dominio de frecuencia usando 
la transformada de Q constante a partir de la cual se la aplican diferentes técnicas para identificar las notas.

\bigskip
En un terreno más general, trabajos como el de \cite{chang2017audio}, exploran la identificación de \textit{covers} utilizando
estructuras más novedosas que no desarrollaremos en este trabajo como son las Redes de Neuronas Convolucionales. Las salidas de este
sistema corresponderían con la probabilidad de ser una \textit{cover} (comparándola con la canción original), y se ordenarían por dicha 
probabilidad elaborando un ranking.

\bigskip
También encontramos la tesis de \cite{klapuri2004signal} que propone un sistema capaz de generar una representación 
simbólica a partir de un audio, centrándose en el desarrollo de los algoritmos que pueden ser usados para detectar y observar sonidos harmónicos en señales polifónicas.
Los cuales fueron evaluados aplicandolos en un programa de transcripción de música para piano implementado y simulado en un entorno Matlab.

\bigskip
En el trabajo de \cite{marolt2002neural} destacamos el uso de sistemas conexionistas para la detección de inicio en señales musicales basandose en la combinacion de un banco de filtros auditivos
, un red neuronal pulsante y un perceptron multicapa. Este uso de sistemas conexionistas también es empleado para sistemas de transcripción de musica de piano polifónico, mostrando ciertas ventajas sobre otros métodos debido a su estructura y 
presentándose como una alternativa viable a los algoritmos ya existentes

\bigskip
El uso de redes de neuronas artificiaes también están presentes en trabajos como \cite{solanki2019music}, que aborda la identificación de
los instrumentos que forman part de piezas polifónicas. Utiliza una red de neuronas convolucional de 8 capas y se apoya en los espectrogramas 
MEL para mapear datos del audio.

\bigskip
Para finalizar, ya en un campo algo más alejado del musical, podemos destacar el trabajo elaborado por \cite{baevski2021unsupervised},
el cual profundiza en el campo de reconocimiento del habla mediante inteligencia artificial.
A diferencia de otros sistemas de reconocimiento, este trabajo no usa datos etiquetados que limiten el reconocimiento a un grupo reducido de idiomas. 
Esta técnica necesita menos requerimientos, aprovechando representaciones auto supervisadas del habla para segmentar el audio y aprender a 
mapear desde estas representaciones a fonemas via \textit{Adversarial Training}.

\bigskip

\newpage
\section{Desarrollo}
\label{Desarrollo}
Para el desarrollo de este sistema utilizaremos un método basado en aproximaciones, es decir, comenzaremos acotando el problema e iremos aumentando
la complejidad a medida que obtenemos resultados satisfatorios.
\subsection{Primera aproximación}
\label{Primera aproximación}

\subsubsection{Descripción}
En esta primera aproximación nos limitaremos a diferenciar únicamente entre dos notas. 
Escogimos las notas \textit{C4} y \textit{A5} de los cuales usaremos 92 y 56 audios de cada una, respectivamente, en total
se utilizarán 148 patrones. En las figuras \ref{fig:c4} y \ref{fig:a5} podemos ver a la izquierda la señal en tiempo y, a la derecha,
la señal en el dominio de la frecuencia.

\begin{figure}[h!]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1.0\linewidth]{c4.pdf}
		\caption{C4}
		\label{fig:c4}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\includegraphics[width=1.0\linewidth]{a5.pdf}
		\caption{A5}
		\label{fig:a5}
	\end{subfigure}
	\caption{Notas en tiempo y frecuencia}
\end{figure}

\bigskip
Dado que cada muestra tiene una duración diferente, decidimos quedarnos solo con los 3 primeros segundos de cada audio (que es donde está la información más
relevante de la nota) y, para la frecuencia, acotaremos cada señal entre 0 y 5000 Hz. Ya que la frecuencia máxima que se alcanza en el 
piano clásico es de 4186 Hz (\textit{C8}) y la más baja, en nuestra base de datos, es de 32.7Hz (\textit{C1}), escogimos un rango
de frecuncias ampliado debido a que es posible que exista información que nos ayude a identificar la nota.

\bigskip
Además, como las notas de un mismo instrumento se diferencian principalmente por la frecuencia (una nota más aguda tiene una mayor frecuencia
y una más grave, una menor), calcularemos de las señales en el dominio del tiempo su relación en el dominio de la frecuencia utilizando la
Transformada de Fourier y, posteriormente, extraeremos las siguientes características:
\begin{itemize}
	\item \textbf{Energia media de la señal}: ya que las señales con más frecuencia (más agudas) tienen más energía, esta característica nos podría
		ayudar a diferenciar entre notas tocadas con la misma intensidad.
	\item \textbf{Media, desviación tipica, y valor máximo de la intensidad en el dominio de la frecuencia, en intervalos no uniformes}: la frecuencia de cada nota
		aumenta de forma exponencial siguiendo la fórmula:

		\begin{equation}
			f_{i+1} = f_{i}\cdot(\sqrt[12]{2}), f_0 = 27.5 Hz
		\end{equation}

		Por ello decidimos dividir el espectro en \textbf{10 intervalos} de longitud variable siguiendo dicha distribución. 
		Podríamos entonces obtener un intervalo donde la media y la desviación típica de la frecuencia fueran más elevados que el resto,
		ayudándonos a identificar la nota.
		
		Los intervalos que usaremos son los siguientes:
		
		\textit{(0.0, 380.3), (380.3, 783.21), (783.21, 1210.08), (1210.08, 1662.33),\newline
		(1662.33, 2141.47), (2141.47, 2649.11), (2649.11, 3186.93), (3186.93, 3756.73), 
		(3756.73, 4360.42) y (4360.42, 5000.0)}
	\item \textbf{Zero-crossing/s}: esta característica determina las veces que la señal, en el dominio del tiempo, toma el valor 0 por segundo.
		Como dicha cracterística nos proporcionaría valores similares a la frecuencia media de la señal, podría contribuír a su correcta clasificación.
\end{itemize}

En lo referente al preprocesado de los datos, nos hemos decidido optar por una \textbf{normalización de media cero},
debido a que los datos no están acotados en un intervalo y pueden tomar cualquier valor, ya sea
en tiempo o en frecuencia. Aunque las frecuencias de las notas sí que están acotadas en un intervalo, en la señal
puede haber ruído que se salga de los valores típicos, por lo que una normalización entre mínimo y máximo no es lo adecuado.

\bigskip
Los parámetros de normalización para cada característica son los siguientes:

(Media $\pm$ Desviación Típica)
\begin{itemize}
	\item E: $0.0045678928 \pm 0.0035726614$
	\item zero-crossing: $1797.2139 \pm 1352.7441$
	\item m1: $16.821161 \pm 11.616611$
	\item m2: $9.4079 \pm 5.8349323$
	\item m3: $14.607474 \pm 11.515968$
	\item m4: $3.8720663 \pm 3.5469663$
	\item m5: $2.3520973 \pm 2.1539617$
	\item m6: $0.48698702 \pm 0.6487291$
	\item m7: $0.7153551 \pm 1.0973071$
	\item m8: $0.40077275 \pm 0.500489$
	\item m9: $0.22367951 \pm 0.3412378$
	\item m10: $0.23234393 \pm 0.5112222$
	\item std1: $54.282375 \pm 46.679535$
	\item std2: $31.582827 \pm 27.185955$
	\item std3: $57.896194 \pm 38.439426$
	\item std4: $11.108885 \pm 12.696077$
	\item std5: $7.0041313 \pm 6.732649$
	\item std6: $0.52131796 \pm 0.72755563$
	\item std7: $2.7318008 \pm 4.6750984$
	\item std8: $0.9234557 \pm 1.2807367$
	\item std9: $0.47755784 \pm 0.89846444$
	\item std10: $0.5695597 \pm 1.2890217$
	\item max1: $832.8222 \pm 779.30615$
	\item max2: $567.7255 \pm 505.1785$
	\item max3: $901.9232 \pm 548.2265$
	\item max4: $192.80989 \pm 237.47154$
	\item max5: $98.938354 \pm 103.55783$
	\item max6: $4.392064 \pm 6.0777674$
	\item max7: $40.596066 \pm 65.99385$
	\item max8: $11.672165 \pm 15.524432$
	\item max9: $5.7904434 \pm 10.440257$
	\item max10: $5.6131926 \pm 11.565159$
\end{itemize}
Donde \textit{E} indica la \textbf{energía de la señal}, zero-crossing indica el número de veces que la señal cruza
el eje horizontal por segundo en el tiempo (\textbf{Zero-crossing/s})
\textit{mi} indica la \textbf{media de la intensidad} en el intervalo \textit{i} en frecuencia, 
\textit{stdi} indica la {desviación típica de la intensidad} en el intervalo \textit{i} en frecuencia
y \textit{maxi} indica el máximo de la intensidad en el intervalo \textit{i} en frecuencia.  

\bigskip
Se van a realizar experimentos sobre los siguientes modelos: RRNNAA, SVM, Árboles de decisión y kNN.

\bigskip
Para los experimentos, se va a realizar \textbf{\textit{cross-validation}} con cada modelo, para así poder evaluar el rendimiento
de cada uno, con independencia de la aleatoriedad que se pueda producir al seleccionar un subconjunto de patrones para test.
En concreto, se realizará un \textbf{\textit{cross-validation}} con \textbf{10 \textit{folds}}. El valor del F1-Score y de la precisión
del modelo será el promedio de dichos valores obtenidos en los \textit{folds}. Para obtener el valor de las métricas en cada fold, 
se computarán para el conjunto de test seleccionado en cada fold.

\bigskip
Además, como el entrenamiento de una RNA es un proceso no determinista, en cada \textit{fold}
tendremos que entrenar la RNA varias veces, y promediar los resultados. Para estos experimentos,
se ha repetido 30 veces el entrenamiento de la RNA en cada \textit{fold}, devolviendo el resultado promedio de esas 30 ejecuciones.

\bigskip
Para poder evaluar el modelo con mejor rendimiento, como ya se ha dicho antes, utilizaremos como medida el promedio
del \textbf{F1-Score} en los \textit{folds}. Si hay empate en dicha media, se elegirá el modelo con menor
desviación típica de la métrica.

\subsubsection{Resultados}
Para permitir la reproducibilidad de los experimentos, se utilizó \textit{100} como semilla de generación de números
aleatorios.

\paragraph{RRNNAA}

Para el entrenamiento de las RRNNAA, se han utilizado los siguientes parámetros en común:
\begin{itemize}
	\item Ratio de aprendizaje: $0.01$
	\item Ratio de patrones para el conjunto de validación: $0.2$.
	\item Máximo número de ciclos (\textit{epochs}) de entrenamiento: $1500$.
	\item Máximo número de ciclos (\textit{epochs}) de entrenamiento sin mejorar el error de validación: $5$.
	\item Algoritmo de optimización: ADAM.
	\item Función de \textit{loss}: \textit{Binary Cross Entropy}.
\end{itemize}
El hiperparámetro que hemos variado ha sido la arquitectura de neuronas a utilizar. Utilizamos 8 arquitecturas distintas,
donde la arquitectura [$i$] denota una RNA con una única capa oculta con $i$ neuronas y la arquitectura [$i$, $j$] 
denota una neurona con dos capas ocultas; con $i$ neuronas en la primera capa oculta y $j$ neuronas en la segunda capa oculta.

Se muestran los resultados de la experimentación en la tabla \ref{Tab:ANN}

\begin{table}[ht]
	\caption{Resultados RRNNA}
	\centering
		 \begin{tabular}{||c c c||}
			 \hline
			 Arquitectura & F1-Score & Precisión  \\ [0.5ex]
			 \hline\hline
			 [2] & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 [4] & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 [8] & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 [2, 4] & $0.9119 \pm 0.12531$ & $0.96487 \pm 0.05054$ \\
			 \hline
			 [2, 8] & $0.90667 \pm 0.14724$ & $0.96524 \pm 0.05412$ \\
			 \hline
			 [4, 2] & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 [4, 4] & $0.99 \pm 0.0225$ & $0.99643 \pm 0.00804$ \\
			 \hline
			 [4, 8] & $0.9621 \pm 0.0974$ & $0.97934 \pm 0.05699$ \\
			 \hline
		 \end{tabular}
	\label{Tab:ANN}
\end{table}

\paragraph{SVM}

Para las máquinas de soporte vectorial hemos utilizado 8 configuraciones distintas de los hiperparámetros de \textit{kernel},
grado del \textit{kernel} (sólo se utiliza en \textit{kernel} polinomial), \textit{gamma} y \textit{C}.

Se muestran los resultados de la experimentación en la tabla \ref{Tab:SVM}


\begin{table}[ht]
\caption{Resultados SVM}
\centering
	 \begin{tabular}{||c c c||}
		 \hline
		 (kernel, grado, gamma, C) & F1-Score & Precisión  \\ [0.5ex]
		 \hline\hline
		 (poly, $3$, $1$, $1$) & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
		 \hline
		 (rbf, $3$, $1$, $1$) & $0.93642 \pm 0.07368$ & $0.94119 \pm 0.07166$ \\
		 \hline
		 (sigmoid, $3$, $1$, $1$) & $0.71875 \pm 0.15823$ & $0.77143 \pm 0.11289$ \\
		 \hline
		 (poly, $5$, $10$, $0.1$) & $0.99 \pm 0.03162$ & $0.98571 \pm 0.04518$ \\
		 \hline
		 (rbf, $3$, $10$, $0.1$) & $0.76689 \pm 0.01542$ & $0.62214 \pm 0.02026$ \\
		 \hline
		 (sigmoid, $3$, $10$, $0.1$) & $0.70059 \pm 0.1406$ & $0.77768 \pm 0.06262$ \\
		 \hline
		 (rbf, $3$, $0.01$, $100$) & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
		 \hline
		 (rbf, $3$, $100$, $0.01$) & $0.76689 \pm 0.01542$ & $0.62214 \pm 0.02026$ \\
		 \hline
	 \end{tabular}
\label{Tab:SVM}
\end{table}

\paragraph{Árboles de decisión}
Para los árboles de decisión hemos utilizado 6 configuraciones distintas del hiperparámetro de profundidad máxima.

Se muestran los resultados de la experimentación en la tabla \ref{Tab:DecisionTree}

\begin{table}[ht]
	\caption{Resultados Árbol de decisión}
	\centering
		 \begin{tabular}{||c c c||}
			 \hline
			 Altura máxima & F1-Score & Precisión  \\ [0.5ex]
			 \hline\hline
			 $2$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 $4$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 $8$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 $16$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 $32$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 $64$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
		 \end{tabular}
	\label{Tab:DecisionTree}
\end{table}

\paragraph{kNN}
Para el modelo kNN hemos utilizado 6 configuraciones distintas del hiperparámetro de k (número de vecinos más cercanos).

Se muestran los resultados de la experimentación en la tabla \ref{Tab:kNN}

\begin{table}[ht]
	\caption{Resultados kNN}
	\centering
		 \begin{tabular}{||c c c||}
			 \hline
			 K & F1-Score & Precisión  \\ [0.5ex]
			 \hline\hline
			 $2$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 $3$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 $5$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 $8$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 $13$ & $1.0 \pm 0.0$ & $1.0 \pm 0.0$ \\
			 \hline
			 $21$ & $0.99091 \pm 0.02875$ & $0.99286 \pm 0.02259$ \\
			 \hline
		 \end{tabular}
	\label{Tab:kNN}
\end{table}

\subsubsection{Discusión}
Los resultados han sido muy buenos, ya que en la mayoría de casos de alcanza una \textbf{precisión} y un \textbf{F1-Score} del 100\% o muy alto. 

\bigskip
En general, los sistemas se equivocan en muy pocos patrones. Esto se puede deber a que el problema escogido en esta aproximación
era muy sencillo y utilizamos un número elevado de características que puedan permitir separar las clases.

\bigskip
En lo referente a las características, han sido correctamente elegidas, ya que alcanzamos una precisión muy alta. Pero también
se puede culpar al elevado número de características que algunos sistemas concretos no funcionen tan bien (por ejemplo, algunos SVM), 
ya que algunas de ellas pueden ser innecesarias o hasta contraproducentes en este sencillo problema. Sería buena opción intentar 
reducir el número de características para futuros problemas, pero hay que tener cuidado, ya que si aumentamos el número de clases a 
clasificar, podría darse el caso de haber eliminado una característica que sí que nos haría falta en un futuro, por lo que de momento 
es mejor no eliminar características.

En concreto, las características que creemos que son las que producen mejores resultados son las que se refieren a los intervalos 
en frecuencia de (0.0, 380.3) y (783.21, 1210.08), ya que es ahí donde está la frecuencia de las notas C4 y A5, respectivamente.
Las características que se corresponden a dichos intervalos son \textit{m1, std1, max1} para el primer intervalo y \textit{m3, std3, max3}
para el segundo intervalo.
Otra característica que podría funcionar sería la frecuencia en la que se alcanza el pico absoluto en intensidad de la señal,
o la media de las K frecuencias con mayor intensidad, sin tener en cuenta la división en intervalos. O también se podría aumentar
el número de intervalos en los que obtener las características, para poder así separar mejor las notas con frecuencias más cercanas.

\bigskip
Todos los algoritmos tienen al menos una configuración con un \textbf{F1-Score} de $1.0 \pm 0.0$, por lo que es complicado encontrar uno que sea el mejor.

\bigskip
Podemos destacar la RNA con una arquitectura de una única capa oculta con 2 neuronas, ya que es un modelo muy sencillo y podemos esperar que, cuanto
más sencillo sea un modelo, mayor será su capacidad de generalización. 

\bigskip 
En la figura \ref{fig:rna_train} podemos ver un gráfico del entrenamiento de dicha rna, donde se puede ver el error
cometido en los conjuntos de test, validación y entrenamiento para cada ciclo de entrenamiento. Este entrenamiento se ha realizado
utilizando todos los patrones, separando un 20\% para el conjunto de test.
Se puede observar que la curva de la gráfica desciende muy rápido, esto se puede deber a que tenemos un ratio de aprendizaje
alto para este problema concreto. Además, se puede ver que se ha producido una parada temprana, ya que el sistema no ha realizado
el máximo número de ciclos de entrenamiento ($1500$ ciclos).

\bigskip
En la figura 5 podemos ver una matriz de confusión para la RNA entrenada anteriormente. Las predicciones se hicieron sobre un conjunto
de test, que supone un 20\% de todos los patrones utilizados. Se utilizó el 80\% de los patrones restantes para el entrenamiento de la RNA,
ya que el conjunto de entrenamiento no se debería utilizar para realizar predicciones.

\begin{figure}[h!]
	\centering
	\includegraphics[width=1.0\linewidth]{best_rna_train.pdf}
	\caption{Entrenamiento RNA }
	\label{fig:rna_train}
\end{figure}

\begin{table}[!ht]
    \centering
    \renewcommand{\arraystretch}{3}
    \begin{tabular}{ll|l|l|}
        
	\multicolumn{2}{c}{}&   \multicolumn{2}{c}{Predicc.}\\
        \multicolumn{2}{c}{}&\multicolumn{2}{c}{{\rotatebox[origin=c]{0}{A5}
            } {\rotatebox[origin=c]{0}{C4}
        }}\\
        \cline{3-4}
        \multirow{2}{*}{{\rotatebox[origin=c]{90}{Real}
        }} & 
        A5&15 & 0  \\ \cline{3-4}
        & C4& 0 & 15 \\ \cline{3-4}
    \end{tabular}
	\caption{Matriz de confusión RNA}
    \label{sa}
\end{table}

\bigskip 
Pero aunque se alcance ya un buen resultado con un modelo sencillo como puede ser la RNA anterior, caben destacar los árboles de decisión,
que son modelos que pueden ofrecer explicabilidad sobre sus predicciones, además de presentar un entrenamiento determinista, por lo que 
si tenemos que elegir el mejor modelo, nos decantaríamos por este (en concreto, el de altura máxima de 2, ya que es el más sencillo), 
ya que presenta también un 100\% de \textbf{F1-Score}.

\bigskip
Aunque si deseamos un modelo con una base matemática más fuerte, en vez de un modelo con una base estadística como puede ser un árbol de regresión,
utilizar una máquina de soporte vectorial con un \textit{kernel} polinomial de grado 3, y ambos valores de \textit{gamma} y \textit{C} de 1, también sería una buena opción. 

Los algoritmos que han funcionado peor han sido ciertas configuraciones de los SVM, en concreto las que utilizan un \textit{kernel} sigmoidal.
Entonces, utilizar un \textit{kernel} sigmoidal no parece ofrecer buenos resultados para estos patrones.


\subsection{Segunda aproximación}
\label{Segunda aproximación}
Como hemos obtenido resultados muy buenos en la aproximación anterior, se va a aumentar la complejidad del problema,
es decir, añadiremos más notas a ser clasificadas.

Las notas que vamos a clasificar son: C1, C2, C3, C4, C5, C6, C7, C8, A1, A2, A3, A4, A5, A6, A7

Intentaremos que el sistema funcione bien con las características que ya tenemos, pero se añadiría alguna más
si vemos que el sistema no funciona bien.

\section{Conclusiones}
\label{Conclusiones}
\section{Trabajo futuro}
\label{Trabajo futuro}

\section{Bibliografía}
\label{Bibliografía}
\printbibliography

\end{document}
